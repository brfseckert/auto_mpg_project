{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    " - *Objective:* Predict Miles Per Gallon of a given vehicle based on other relevant attributes provided\n",
    " - The data used for the project comes from the UCI Machine Learning Repository and can be found in the link below:\n",
    "   http://archive.ics.uci.edu/ml/datasets/Auto+MPG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring dependancies\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the column names\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "# reading the .data file using pandas\n",
    "df = pd.read_csv('./auto-mpg.data', names=cols, na_values = \"?\",\n",
    "                comment = '\\t',\n",
    "                sep= \" \",\n",
    "                skipinitialspace=True)\n",
    "#making a copy of the dataframe\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking outliers in the Horsepower column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the horsepower\n",
    "sns.boxplot(df['Horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the outliers problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df['Horsepower'].median()\n",
    "df['Horsepower'] = df['Horsepower'].fillna(median) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 columns are categorical cylinders and origin\n",
    "df['Cylinders'].value_counts() / len(df['Cylinders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Origin'].value_counts() / len(df['Origin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\", \"Horsepower\"]], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test data split\n",
    " - In order to ensure that the dataset is properely split, we use stratified sampeling. Here is a definition of the method: \"Stratified Sampling â€” We create homogeneous subgroups called strata from the overall population and sample the right number of instances to each stratum to ensure that the test set is representative of the overall population\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['Cylinders']):\n",
    "    train_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['Cylinders'].value_counts() / len(train_set['Cylinders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Cylinders'].value_counts() / len(test_set['Cylinders'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace number by country to then create a one-hot-encoding\n",
    "train_set['Origin'] = train_set['Origin'].map({1: 'India', 2: 'USA', 3 : 'Germany'})\n",
    "train_set = get_dummies(train_set, prefix ='', prefix_sep='')\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new variables for testing\n",
    "df['displacement_on_power'] = df['Displacement'] / df['Horsepower']\n",
    "df['weight_on_cylinder'] = df['Weight'] / df['Cylinders']\n",
    "df['acceleration_on_power'] = df['Acceleration'] / df['Horsepower']\n",
    "df['acceleration_on_cyl'] = df['Acceleration'] / df['Cylinders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlation_matrix['MPG'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- This step performs the following steps:\n",
    " - adjust the origin column\n",
    " - handle the missing values \n",
    " - add the feature engineering variables\n",
    " - adjust the ctaegorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dic = {1: 'India', 2: 'USA', 3 : 'Germany'}\n",
    "\n",
    "def _encode_origin_column(df):\n",
    "    df['Origin'] = df['Origin'].map(origin_dic)\n",
    "    return df\n",
    "\n",
    "def _adjust_missing_values(df):\n",
    "    numeric_columns = df.select_dtypes(['float64','int64']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "    return df\n",
    "\n",
    "def _add_custom_variables(df):\n",
    "    df = df.assign(acceleration_on_cyl=df['Acceleration']/df['Cylinders'],\n",
    "                   acceleration_on_power=df['Acceleration'] / df['Horsepower'])\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    \n",
    "    df = (\n",
    "        df.pipe(_encode_origin_column).\n",
    "        pipe(_adjust_missing_values).\n",
    "        pipe(_add_custom_variables)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_columns(df):\n",
    "    numeric_columns = df.select_dtypes(['float64','int64']).columns\n",
    "    category_columns = ['Origin']\n",
    "    \n",
    "    transformer = ColumnTransformer([\n",
    "                    ('standard_scalar',StandardScaler(), list(numeric_columns)),\n",
    "                    ('one_hot_encoding',OneHotEncoder(),category_columns)\n",
    "                ])\n",
    "    return transformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['Cylinders']):\n",
    "    train_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]\n",
    "    \n",
    "train_data = train_set.drop('MPG',axis=1)\n",
    "train_data_labels = train_set['MPG']\n",
    "test_data = test_set.drop('MPG',axis=1)\n",
    "test_data_labels = test_set['MPG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = prepare_data(train_data)\n",
    "prepared_train_data  = transform_columns(df_train_data)\n",
    "df_test_data = prepare_data(test_data)\n",
    "prepared_test_data  = transform_columns(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85657842, -1.07804475, -1.15192977, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.85657842, -1.1174582 , -0.9900351 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.85657842, -0.3587492 , -0.31547399, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.85657842, -0.56566984, -0.53133355, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.85657842, -0.78244384, -0.23452666, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression rmse mean score is 3.0757081793709324\n",
      "Decicion Tree rmse mean score is 3.3799747629926045\n",
      "SVR rmse mean score is 3.164117785619293\n",
      "Random Forest rmse mean score is 2.57934759746959\n"
     ]
    }
   ],
   "source": [
    "models_dic = {'Linear Regression':LinearRegression(),\n",
    "              'Decicion Tree': DecisionTreeRegressor(),\n",
    "              'SVR':SVR(),\n",
    "              'Random Forest':RandomForestRegressor()}\n",
    "\n",
    "for k, v in models_dic.items():\n",
    "    scores = cross_val_score(v, prepared_train_data, train_data_labels, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "    rmse_score = np.sqrt(-scores).mean()\n",
    "    print('{model} rmse mean score is {score}'.format(model=k,score=rmse_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True,\n",
    "                           cv=10,\n",
    "                          )\n",
    "grid_search.fit(prepared_train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best pararmets\n",
    "final_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = final_model.predict(prepared_test_data)\n",
    "final_mse = mean_squared_error(test_data_labels, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.997825369237583"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mpg(data, model):\n",
    "    \n",
    "    if type(data) == dict:\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = data\n",
    "        \n",
    "    prepared_data = prepare_data(df)\n",
    "    prepared_data = transform_columns(prepared_data)\n",
    "    \n",
    "    return model.predict(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking it on a random sample\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.16666667, 17.01      , 20.41666667])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_mpg(vehicle_config,final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.16666667, 17.01      , 20.41666667])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "predict_mpg(vehicle_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"mpg_prediction\": [\\n    33.16666666666666, \\n    17.009999999999998, \\n    20.416666666666668\\n  ]\\n}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "\n",
    "url = 'http://localhost:9696/predict'\n",
    "r = requests.post(url, json = vehicle_config)\n",
    "r.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
